{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34130473",
   "metadata": {},
   "source": [
    "## Error Analysis and Grad-CAM Interpretation\n",
    "\n",
    "This notebook documents the **error analysis and interpretability workflow**\n",
    "for the trained baseline CNN model.\n",
    "\n",
    "To ensure stability and reproducibility:\n",
    "- Model training and evaluation are performed in `02_baseline_cnn.ipynb`\n",
    "- Grad-CAM visualizations and inference are executed via an external script\n",
    "  (`scripts/run_gradcam.py`) to avoid GPU and kernel instability in notebooks\n",
    "\n",
    "This notebook focuses on:\n",
    "- Dataset reconstruction and label mapping\n",
    "- Qualitative interpretation of Grad-CAM outputs\n",
    "- Analysis of correct vs incorrect predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f4a2b4",
   "metadata": {},
   "source": [
    "##### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46bd54ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from src.data_loader import collect_image_paths, stratified_split\n",
    "from src.models import build_baseline_cnn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d75f81",
   "metadata": {},
   "source": [
    "##### Dataset Reconstruction and Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1625dcfd",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Dataset and split\n",
    "DATASET_PATH = \"../data/raw/PlantVillage\"\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "image_paths, labels = collect_image_paths(DATASET_PATH)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = stratified_split(\n",
    "    image_paths, labels\n",
    ")\n",
    "\n",
    "# Encode class labels\n",
    "class_names = sorted(set(labels))\n",
    "class_to_index = {name: idx for idx, name in enumerate(class_names)}\n",
    "index_to_class = {idx: name for name, idx in class_to_index.items()}\n",
    "\n",
    "y_test_encoded = np.array([class_to_index[y] for y in y_test])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63b1730",
   "metadata": {},
   "source": [
    "## Grad-CAM Execution Strategy\n",
    "\n",
    "Inference and Grad-CAM visualization are executed via\n",
    "`scripts/run_gradcam.py` instead of this notebook.\n",
    "\n",
    "**Reason:**\n",
    "- Prevents Jupyter kernel crashes during gradient-based visualization\n",
    "- Enables stable batch-wise Grad-CAM generation\n",
    "- Allows saving correct and incorrect predictions reproducibly\n",
    "\n",
    "Generated outputs are stored under:\n",
    "- `results/gradcam/correct/`\n",
    "- `results/gradcam/incorrect/`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a553d6",
   "metadata": {},
   "source": [
    "## Manual Grad-CAM Inspection â€” Observations\n",
    "\n",
    "### Correct Predictions\n",
    "- Heatmaps are localized on lesion regions\n",
    "- Attention aligns with infected or discolored areas\n",
    "- Minimal activation on background\n",
    "\n",
    "### Incorrect Predictions\n",
    "- Heatmaps activate background or leaf boundaries\n",
    "- Attention focuses on veins or edges instead of lesions\n",
    "- Confusions occur between visually similar diseases\n",
    "  (e.g., Early blight vs Late blight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b3938f",
   "metadata": {},
   "source": [
    "## Error Summary\n",
    "\n",
    "| Case Type | Observation | Interpretation |\n",
    "|---------|------------|---------------|\n",
    "| Correct | Heatmap focused on lesion regions | Model learned disease-specific cues |\n",
    "| Incorrect | Activation on background | Weak localization / dataset bias |\n",
    "| Incorrect | Confusion between similar diseases | High visual similarity across classes |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc151d6",
   "metadata": {},
   "source": [
    "## Reference: Baseline Training Behavior\n",
    "\n",
    "Training dynamics of the baseline CNN were analyzed in\n",
    "`02_baseline_cnn.ipynb`.\n",
    "\n",
    "Saved plots:\n",
    "- `results/plots/baseline_accuracy_curve.png`\n",
    "- `results/plots/baseline_loss_curve.png`\n",
    "\n",
    "These plots confirm stable convergence prior to error analysis.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
